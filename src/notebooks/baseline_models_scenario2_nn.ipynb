{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import json\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.layers import Lambda\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# all the functions from helpers.py\n",
    "from helpers_scenario2_redes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_folder = '../data/raw/scenario_2/fold_0/train/annotations/'\n",
    "# physiology_folder = \"../data/preprocessed/cleaned/scenario_1/fold_0/train/physiology/\" #'../data/raw/scenario_1/train/physiology/'\n",
    "physiology_folder = \"../data/preprocessed/cleaned_and_prepro_improved/scenario_2/fold_0/train/physiology/\" #'../data/raw/scenario_1/train/physiology/'data\\preprocessed\\\n",
    "\n",
    "df_physiology = load_read_and_append_csvs(physiology_folder)\n",
    "df_annotations = load_read_and_append_csvs(annotations_folder)\n",
    "\n",
    "videos = df_physiology.video.unique()\n",
    "subjects = df_physiology.subject.unique()\n",
    "\n",
    "splits = split_subjects_train_test(subjects, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#videos = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1\n",
    "from keras.layers import Activation\n",
    "\n",
    "def create_cnn_lstm_model(input_shape, lstm_units=64, dropout_rate=0.3, kernel_regularizer_l1=0.001):\n",
    "    input_signal = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv1D(16, 5, padding='same')(input_signal)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = Conv1D(8, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = LSTM(lstm_units)(x)\n",
    "\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l1(kernel_regularizer_l1))(x)\n",
    "\n",
    "    return Model(inputs=input_signal, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed, ThreadPoolExecutor\n",
    "import threading\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "\n",
    "# Initialize an empty dictionary to store the video results\n",
    "video_results = {}\n",
    "\n",
    "# Wrap the outer loop with tqdm\n",
    "for video in tqdm(videos, desc=\"Processing videos\", unit=\"video\", bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % ('\\033[32m', '\\033[0m')):\n",
    "    print(f\"Processing video: {video}\")\n",
    "\n",
    "    df_physiology_video = df_physiology.loc[df_physiology.video == video]\n",
    "    df_annotations_video = df_annotations.loc[df_annotations.video == video]\n",
    "\n",
    "    rmses = []\n",
    "\n",
    "    for split_index, split in enumerate(splits):\n",
    "        # print(split)\n",
    "\n",
    "        X_train, X_test, y_train, y_test, numeric_column_indices, categorical_column_indices = preprocess(\n",
    "            df_physiology_video.copy(), df_annotations_video.copy(), split=split, predictions_cols=['arousal', 'valence'], aggregate=None,\n",
    "            window_duration=10000, resample_rate=100)\n",
    "\n",
    "        print(\"X_test shape:\", X_test.shape)\n",
    "        print(\"y_test shape:\", y_test.shape)\n",
    "                \n",
    "        # Extract arousal and valence values from y_train and y_test\n",
    "        y_arousal_train = y_train[:, 0]\n",
    "        y_valence_train = y_train[:, 1]\n",
    "        y_arousal_test = y_test[:, 0]\n",
    "        y_valence_test = y_test[:, 1]\n",
    "\n",
    "        input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "        cnn_model = create_cnn_lstm_model(input_shape)\n",
    "\n",
    "        # Create separate heads for valence and arousal prediction, using sigmoid activation and scaling the output\n",
    "        valence_output = Dense(1, activation='sigmoid')(cnn_model.output)\n",
    "        valence_output = Lambda(lambda x: x * 8 + 1, name='valence_output')(valence_output)\n",
    "\n",
    "        arousal_output = Dense(1, activation='sigmoid')(cnn_model.output)\n",
    "        arousal_output = Lambda(lambda x: x * 8 + 1, name='arousal_output')(arousal_output)\n",
    "\n",
    "        # Combine the model\n",
    "        final_model = Model(inputs=cnn_model.input, outputs=[valence_output, arousal_output])\n",
    "\n",
    "        # Compile the model\n",
    "        final_model.compile(optimizer='adam',\n",
    "                            loss={'valence_output': 'mse',\n",
    "                                'arousal_output': 'mse'},\n",
    "                            metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "        # Set up early stopping\n",
    "        early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "        # Train the model\n",
    "        history = final_model.fit(X_train, {'valence_output': y_valence_train, 'arousal_output': y_arousal_train},\n",
    "                                validation_split=0.2, epochs=50, batch_size=32,\n",
    "                                callbacks=[early_stopping_callback])\n",
    "        \n",
    "        evaluation = final_model.evaluate(X_test, [y_valence_test, y_arousal_test])\n",
    "\n",
    "        # Save the evaluation results in the dictionary\n",
    "        key = f\"video_{video}_split_{split_index}\"\n",
    "        results[key] = {\n",
    "            'valence_output_root_mean_squared_error': evaluation[3],\n",
    "            'arousal_output_root_mean_squared_error': evaluation[4]\n",
    "        }\n",
    "\n",
    "    # Calculate the average of the evaluation results\n",
    "    evaluation_sum = np.array([list(rmse_dict.values()) for rmse_dict in results.values()]).sum(axis=0)\n",
    "    average_evaluation = evaluation_sum / len(splits)\n",
    "\n",
    "    # Save the results for the current video\n",
    "    video_results[f\"video_{video}\"] = results\n",
    "\n",
    "    # Save the average evaluation in the dictionary\n",
    "    video_results[f\"video_{video}_average\"] = {\n",
    "        'valence_output_root_mean_squared_error': average_evaluation[0],\n",
    "        'arousal_output_root_mean_squared_error': average_evaluation[1]\n",
    "    }\n",
    "\n",
    "    # Reset the results dictionary for the next video\n",
    "    results = {}\n",
    "\n",
    "# Save the video_results dictionary to a JSON file\n",
    "with open('results_separate_videos.json', 'w') as outfile:\n",
    "    json.dump(video_results, outfile, indent=4)\n",
    "\n",
    "# Print the final results\n",
    "for video_key, video_value in video_results.items():\n",
    "    print(f\"{video_key}: {video_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results for each split:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_model.evaluate(X_test, [y_valence_test, y_arousal_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_valence_train shape:\", y_valence_train.shape)\n",
    "print(\"y_arousal_train shape:\", y_arousal_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_valence_test shape:\", y_valence_test.shape)\n",
    "print(\"y_arousal_test shape:\", y_arousal_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[split for split_index, split in enumerate(splits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.swapaxes(X_test, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_model.evaluate(X_test, [y_valence_test, y_arousal_test]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(y_valence_test.shape)\n",
    "print(y_arousal_test.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
