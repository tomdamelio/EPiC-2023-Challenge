{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import json\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# all the functions from helpers.py\n",
    "from helpers_scenario2_redes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_folder = '../data/raw/scenario_2/fold_0/train/annotations/'\n",
    "# physiology_folder = \"../data/preprocessed/cleaned/scenario_1/fold_0/train/physiology/\" #'../data/raw/scenario_1/train/physiology/'\n",
    "physiology_folder = \"../data/preprocessed/cleaned_and_prepro_improved/scenario_2/fold_0/train/physiology/\" #'../data/raw/scenario_1/train/physiology/'data\\preprocessed\\\n",
    "\n",
    "df_physiology = load_read_and_append_csvs(physiology_folder)\n",
    "df_annotations = load_read_and_append_csvs(annotations_folder)\n",
    "\n",
    "videos = df_physiology.video.unique()\n",
    "subjects = df_physiology.subject.unique()\n",
    "\n",
    "splits = split_subjects_train_test(subjects, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CNN model\n",
    "def create_cnn_model(input_shape):\n",
    "    input_signal = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv1D(24, 5, padding='same')(input_signal)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(16, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(8, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    f_peripheral = Dense(128, activation='relu')(x)\n",
    "\n",
    "    return Model(inputs=input_signal, outputs=f_peripheral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   0%|\u001b[32m          \u001b[0m| 0/1 [00:00<?, ?video/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: 0\n",
      "Epoch 1/50\n",
      "25/25 [==============================] - 14s 449ms/step - loss: 190.0059 - valence_output_loss: 133.1490 - arousal_output_loss: 56.8570 - valence_output_root_mean_squared_error: 11.5390 - arousal_output_root_mean_squared_error: 7.5404 - val_loss: 3548.8140 - val_valence_output_loss: 150.8290 - val_arousal_output_loss: 3397.9851 - val_valence_output_root_mean_squared_error: 12.2812 - val_arousal_output_root_mean_squared_error: 58.2922\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 11s 423ms/step - loss: 1.7055 - valence_output_loss: 1.5941 - arousal_output_loss: 0.1114 - valence_output_root_mean_squared_error: 1.2626 - arousal_output_root_mean_squared_error: 0.3338 - val_loss: 2340.1660 - val_valence_output_loss: 7.2825 - val_arousal_output_loss: 2332.8833 - val_valence_output_root_mean_squared_error: 2.6986 - val_arousal_output_root_mean_squared_error: 48.2999\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 0.1352 - valence_output_loss: 0.0979 - arousal_output_loss: 0.0373 - valence_output_root_mean_squared_error: 0.3129 - arousal_output_root_mean_squared_error: 0.1930 - val_loss: 1614.2496 - val_valence_output_loss: 12.8864 - val_arousal_output_loss: 1601.3633 - val_valence_output_root_mean_squared_error: 3.5898 - val_arousal_output_root_mean_squared_error: 40.0170\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 13s 509ms/step - loss: 0.0625 - valence_output_loss: 0.0325 - arousal_output_loss: 0.0300 - valence_output_root_mean_squared_error: 0.1802 - arousal_output_root_mean_squared_error: 0.1732 - val_loss: 873.2458 - val_valence_output_loss: 27.9315 - val_arousal_output_loss: 845.3144 - val_valence_output_root_mean_squared_error: 5.2850 - val_arousal_output_root_mean_squared_error: 29.0743\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 13s 508ms/step - loss: 0.0099 - valence_output_loss: 0.0061 - arousal_output_loss: 0.0038 - valence_output_root_mean_squared_error: 0.0782 - arousal_output_root_mean_squared_error: 0.0617 - val_loss: 516.6243 - val_valence_output_loss: 40.5028 - val_arousal_output_loss: 476.1215 - val_valence_output_root_mean_squared_error: 6.3642 - val_arousal_output_root_mean_squared_error: 21.8202\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 13s 521ms/step - loss: 0.0032 - valence_output_loss: 6.8554e-04 - arousal_output_loss: 0.0025 - valence_output_root_mean_squared_error: 0.0262 - arousal_output_root_mean_squared_error: 0.0502 - val_loss: 301.4374 - val_valence_output_loss: 44.1248 - val_arousal_output_loss: 257.3127 - val_valence_output_root_mean_squared_error: 6.6426 - val_arousal_output_root_mean_squared_error: 16.0410\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 12s 499ms/step - loss: 0.0027 - valence_output_loss: 4.8571e-04 - arousal_output_loss: 0.0023 - valence_output_root_mean_squared_error: 0.0220 - arousal_output_root_mean_squared_error: 0.0475 - val_loss: 174.5774 - val_valence_output_loss: 44.8965 - val_arousal_output_loss: 129.6809 - val_valence_output_root_mean_squared_error: 6.7005 - val_arousal_output_root_mean_squared_error: 11.3878\n",
      "Epoch 8/50\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed, ThreadPoolExecutor\n",
    "import threading\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "# Wrap the outer loop with tqdm\n",
    "for video in tqdm(videos, desc=\"Processing videos\", unit=\"video\", bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % ('\\033[32m', '\\033[0m')):\n",
    "    print(f\"Processing video: {video}\")\n",
    "\n",
    "    df_physiology_video = df_physiology.loc[df_physiology.video == video]\n",
    "    df_annotations_video = df_annotations.loc[df_annotations.video == video]\n",
    "\n",
    "    del df_annotations\n",
    "    del df_physiology\n",
    "\n",
    "    rmses = []\n",
    "\n",
    "    for split in splits:\n",
    "        # print(split)\n",
    "\n",
    "        X_train, X_test, y_train, y_test, numeric_column_indices, categorical_column_indices = preprocess(\n",
    "            df_physiology_video.copy(), df_annotations_video.copy(), split=split, predictions_cols=['arousal', 'valence'], aggregate=None,\n",
    "            window_duration=10000, resample_rate=100)\n",
    "\n",
    "        del df_annotations_video\n",
    "        del df_physiology_video\n",
    "\n",
    "        # Extract arousal and valence values from y_train and y_test\n",
    "        y_arousal_train = y_train[:, 0]\n",
    "        y_valence_train = y_train[:, 1]\n",
    "        y_arousal_test = y_test[:, 0]\n",
    "        y_valence_test = y_test[:, 1]\n",
    "\n",
    "        input_shape = (X_train.shape[1], X_train.shape[2])  # Updated input shape\n",
    "        cnn_model = create_cnn_model(input_shape)\n",
    "\n",
    "        # Create separate heads for valence and arousal prediction\n",
    "        valence_output = Dense(1, activation='linear', name='valence_output')(cnn_model.output)\n",
    "        arousal_output = Dense(1, activation='linear', name='arousal_output')(cnn_model.output)\n",
    "\n",
    "        # Combine the model\n",
    "        final_model = Model(inputs=cnn_model.input, outputs=[valence_output, arousal_output])\n",
    "\n",
    "        # Compile the model\n",
    "        final_model.compile(optimizer='adam',\n",
    "                            loss={'valence_output': 'mse',\n",
    "                            'arousal_output': 'mse'},\n",
    "                            metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "        # Set up early stopping\n",
    "        early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "        # Train the model\n",
    "        history = final_model.fit(X_train, {'valence_output': y_valence_train, 'arousal_output': y_arousal_train},\n",
    "                                validation_split=0.2, epochs=50, batch_size=32,\n",
    "                                callbacks=[early_stopping_callback])\n",
    "        \n",
    "        print(final_model.evaluate(X_test, [y_valence_test, y_arousal_test]))\n",
    "\n",
    "        #rmse = ...\n",
    "\n",
    "        #rmses.append(rmse)\n",
    "\n",
    "    #average_rmse = np.mean(rmses, axis=0)\n",
    "\n",
    "    # CREAR UNA FORMA DE GUARDAR CORRIDAS EN JSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
