{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import json\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# all the functions from helpers.py\n",
    "from helpers_scenario2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_folder = '../data/raw/scenario_2/fold_0/train/annotations/'\n",
    "# physiology_folder = \"../data/preprocessed/cleaned/scenario_1/fold_0/train/physiology/\" #'../data/raw/scenario_1/train/physiology/'\n",
    "physiology_folder = \"../data/preprocessed/cleaned_and_prepro_improved/scenario_2/fold_0/train/physiology/\" #'../data/raw/scenario_1/train/physiology/'data\\preprocessed\\\n",
    "\n",
    "df_physiology = load_read_and_append_csvs(physiology_folder)\n",
    "df_annotations = load_read_and_append_csvs(annotations_folder)\n",
    "\n",
    "videos = df_physiology.video.unique()\n",
    "subjects = df_physiology.subject.unique()\n",
    "\n",
    "splits = split_subjects_train_test(subjects, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   0%|\u001b[32m          \u001b[0m| 0/8 [00:00<?, ?video/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [1.61068877 1.42656984]. \n",
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [1.59578232 1.38310135]. \n",
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [1.58737016 1.37840548]. \n",
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [1.58779583 1.38940398]. \n",
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [1.60697564 1.38698758]. \n",
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [1.59543335 1.40393656]. \n",
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [2.22707204 1.71707276]. \n",
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [2.23855819 1.72776679]. \n",
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [1.59555911 1.39289243]. \n",
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [1.58990855 1.37950303]. \n",
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [2.30474008 1.72839019]. \n",
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [2.29796501 1.75174908]. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x1eedec2e700 state=finished returned dict>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xochipilli\\Anaconda3\\lib\\concurrent\\futures\\_base.py\", line 329, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\xochipilli\\AppData\\Local\\Temp\\ipykernel_9312\\296866871.py\", line 131, in callback\n",
      "    all_results[f\"{annotation_file}_{physiology_file}\"] = results\n",
      "NameError: name 'annotation_file' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [2.19909977 2.37622469]. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x1eedec2ea60 state=finished returned dict>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xochipilli\\Anaconda3\\lib\\concurrent\\futures\\_base.py\", line 329, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\xochipilli\\AppData\\Local\\Temp\\ipykernel_9312\\296866871.py\", line 131, in callback\n",
      "    all_results[f\"{annotation_file}_{physiology_file}\"] = results\n",
      "NameError: name 'annotation_file' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [2.2001147 2.3910663]. \n",
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [2.23384277 1.7329476 ]. \n",
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [2.22784096 1.72333922]. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x1eedec28580 state=finished returned dict>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xochipilli\\Anaconda3\\lib\\concurrent\\futures\\_base.py\", line 329, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\xochipilli\\AppData\\Local\\Temp\\ipykernel_9312\\296866871.py\", line 131, in callback\n",
      "    all_results[f\"{annotation_file}_{physiology_file}\"] = results\n",
      "NameError: name 'annotation_file' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [2.21171714 2.39760245]. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x1eedec28be0 state=finished returned dict>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xochipilli\\Anaconda3\\lib\\concurrent\\futures\\_base.py\", line 329, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\xochipilli\\AppData\\Local\\Temp\\ipykernel_9312\\296866871.py\", line 131, in callback\n",
      "    all_results[f\"{annotation_file}_{physiology_file}\"] = results\n",
      "NameError: name 'annotation_file' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [2.20726787 2.37040078]. \n",
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [2.2994884  1.74047784]. \n",
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [2.29642841 1.74445212]. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x1eedec1bd00 state=finished returned dict>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xochipilli\\Anaconda3\\lib\\concurrent\\futures\\_base.py\", line 329, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\xochipilli\\AppData\\Local\\Temp\\ipykernel_9312\\296866871.py\", line 131, in callback\n",
      "    all_results[f\"{annotation_file}_{physiology_file}\"] = results\n",
      "NameError: name 'annotation_file' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [2.21176836 2.39644325]. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x1eedec1b190 state=finished returned dict>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xochipilli\\Anaconda3\\lib\\concurrent\\futures\\_base.py\", line 329, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\xochipilli\\AppData\\Local\\Temp\\ipykernel_9312\\296866871.py\", line 131, in callback\n",
      "    all_results[f\"{annotation_file}_{physiology_file}\"] = results\n",
      "NameError: name 'annotation_file' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [2.19277176 2.4024212 ]. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x1eedec116d0 state=finished returned dict>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xochipilli\\Anaconda3\\lib\\concurrent\\futures\\_base.py\", line 329, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\xochipilli\\AppData\\Local\\Temp\\ipykernel_9312\\296866871.py\", line 131, in callback\n",
      "    all_results[f\"{annotation_file}_{physiology_file}\"] = results\n",
      "NameError: name 'annotation_file' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [2.20157716 2.35838387]. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x1eedec1b520 state=finished returned dict>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xochipilli\\Anaconda3\\lib\\concurrent\\futures\\_base.py\", line 329, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\xochipilli\\AppData\\Local\\Temp\\ipykernel_9312\\296866871.py\", line 131, in callback\n",
      "    all_results[f\"{annotation_file}_{physiology_file}\"] = results\n",
      "NameError: name 'annotation_file' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: RandomForestRegressor. Average Root Mean Squared Error per output: [2.18378513 2.37790257]. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: XGBRegressor. Average Root Mean Squared Error per output: [1.53574151 1.27288891]. \n",
      "Testing model: XGBRegressor. Average Root Mean Squared Error per output: [1.57765863 1.28840772]. \n",
      "Testing model: XGBRegressor. Average Root Mean Squared Error per output: [1.52516919 1.99567926]. \n",
      "Testing model: XGBRegressor. Average Root Mean Squared Error per output: [1.5238566 1.9820819]. \n",
      "Testing model: XGBRegressor. Average Root Mean Squared Error per output: [2.81074562 1.84558854]. \n",
      "Testing model: XGBRegressor. Average Root Mean Squared Error per output: [2.03638729 1.84569017]. \n",
      "Testing model: XGBRegressor. Average Root Mean Squared Error per output: [2.87459973 1.8372276 ]. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x1eedec2ebe0 state=finished returned dict>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xochipilli\\Anaconda3\\lib\\concurrent\\futures\\_base.py\", line 329, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\xochipilli\\AppData\\Local\\Temp\\ipykernel_9312\\296866871.py\", line 131, in callback\n",
      "    all_results[f\"{annotation_file}_{physiology_file}\"] = results\n",
      "NameError: name 'annotation_file' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: XGBRegressor. Average Root Mean Squared Error per output: [1.67468966 2.20656443]. \n",
      "Testing model: XGBRegressor. Average Root Mean Squared Error per output: [2.05508582 1.84557407]. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x1eedec2e520 state=finished returned dict>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xochipilli\\Anaconda3\\lib\\concurrent\\futures\\_base.py\", line 329, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\xochipilli\\AppData\\Local\\Temp\\ipykernel_9312\\296866871.py\", line 131, in callback\n",
      "    all_results[f\"{annotation_file}_{physiology_file}\"] = results\n",
      "NameError: name 'annotation_file' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: XGBRegressor. Average Root Mean Squared Error per output: [1.81401144 2.16036702]. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x1eee01d5820 state=finished returned dict>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xochipilli\\Anaconda3\\lib\\concurrent\\futures\\_base.py\", line 329, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\xochipilli\\AppData\\Local\\Temp\\ipykernel_9312\\296866871.py\", line 131, in callback\n",
      "    all_results[f\"{annotation_file}_{physiology_file}\"] = results\n",
      "NameError: name 'annotation_file' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: XGBRegressor. Average Root Mean Squared Error per output: [1.68312647 2.17241916]. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x1eee01d50a0 state=finished returned dict>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xochipilli\\Anaconda3\\lib\\concurrent\\futures\\_base.py\", line 329, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\xochipilli\\AppData\\Local\\Temp\\ipykernel_9312\\296866871.py\", line 131, in callback\n",
      "    all_results[f\"{annotation_file}_{physiology_file}\"] = results\n",
      "NameError: name 'annotation_file' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: XGBRegressor. Average Root Mean Squared Error per output: [1.82511578 2.16164041]. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed, ThreadPoolExecutor\n",
    "import threading\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "\n",
    "num_cpu_cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Define aggregate metric combinations\n",
    "aggregate_combinations = [\n",
    "    # ['enlarged'],\n",
    "    # ['mean'],\n",
    "    # ['std'],\n",
    "    # ['max'],\n",
    "    ['min'],\n",
    "    # ['mean', 'std'],\n",
    "    # ['mean', 'max'],\n",
    "    # ['mean', 'min'],\n",
    "    # ['std', 'max'],\n",
    "    # ['std', 'min'],\n",
    "    # ['max', 'min'],\n",
    "    ['mean', 'std', 'max', 'min']\n",
    "]\n",
    "\n",
    "# Define models and hyperparameters\n",
    "models_hyperparameters = [\n",
    "    # (LinearRegression, {}),\n",
    "    # (SVR, {\n",
    "    #     'kernel': ['linear', 'rbf'],\n",
    "    #     'C': [0.1, 1, 10],\n",
    "    #     'epsilon': [0.1, 1],\n",
    "    #     'gamma': ['scale', 'auto'],  # Only used for 'rbf' kernel\n",
    "    # }),\n",
    "    (RandomForestRegressor, {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [10, None],\n",
    "        'min_samples_split': [2, 5],\n",
    "        # 'min_samples_leaf': [1, 2],\n",
    "        # 'max_features': ['auto', 'sqrt'],\n",
    "    }),\n",
    "    (XGBRegressor, {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [6, 10],\n",
    "    #     'learning_rate': [0.01, 0.1],\n",
    "    #     'subsample': [0.5, 0.8],\n",
    "        # 'colsample_bytree': [0.5, 0.8],\n",
    "        # 'reg_alpha': [0, 0.1],\n",
    "        # 'reg_lambda': [0.1, 1],\n",
    "    }),\n",
    "]\n",
    "\n",
    "# Define a function to process a single hyperparameter set\n",
    "def process_hp_set(hp_set, model, hyperparameters, iter_aggregate, splits, df_physiology_video, df_annotations_video):\n",
    "    hp_dict = dict(zip(hyperparameters.keys(), hp_set))\n",
    "    model_name = model.__name__\n",
    "\n",
    "    print(f\"Testing model: {model_name} with hyperparameters: {hp_dict} and aggregate: {iter_aggregate}\")\n",
    "\n",
    "    rmses = []\n",
    "    for split in splits:\n",
    "        # print(split)\n",
    "\n",
    "        X_train, X_test, y_train, y_test, numeric_column_indices, categorical_column_indices = preprocess(\n",
    "            df_physiology_video.copy(), df_annotations_video.copy(), split=split, predictions_cols=['arousal', 'valence'], aggregate=iter_aggregate,\n",
    "            window_duration=10000, resample_rate=100)\n",
    "\n",
    "        rmse = time_series_cross_validation_with_hyperparameters(\n",
    "            X_train, X_test, y_train, y_test, model, hp_dict, n_jobs=1,\n",
    "            numeric_column_indices=numeric_column_indices,\n",
    "            categorical_column_indices=categorical_column_indices)\n",
    "\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    average_rmse = np.mean(rmses, axis=0)\n",
    "\n",
    "    if y_train.ndim > 1 and y_train.shape[1] > 1:\n",
    "        # Unpack the average_rmse array into separate keys in the result dictionary\n",
    "        result = {\n",
    "            'model': model_name,\n",
    "            'hyperparameters': hp_dict,\n",
    "            'aggregate': iter_aggregate,\n",
    "            'average_rmse_arousal': average_rmse[0],\n",
    "            'average_rmse_valence': average_rmse[1],\n",
    "        }\n",
    "    else:\n",
    "        result = {\n",
    "            'model': model_name,\n",
    "            'hyperparameters': hp_dict,\n",
    "            'aggregate': iter_aggregate,\n",
    "            'average_rmse': average_rmse\n",
    "        }\n",
    "\n",
    "    return result\n",
    "\n",
    "# Initialize an empty DataFrame for the best results and a dictionary for all results\n",
    "best_results_df = pd.DataFrame()\n",
    "all_results = {}\n",
    "\n",
    "# Wrap the outer loop with tqdm\n",
    "for video in tqdm(videos, desc=\"Processing videos\", unit=\"video\", bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % ('\\033[32m', '\\033[0m')):\n",
    "    print(f\"Processing video: {video}\")\n",
    "\n",
    "    df_physiology_video = df_physiology.loc[df_physiology.video == video]\n",
    "    df_annotations_video = df_annotations.loc[df_annotations.video == video]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for iter_aggregate in aggregate_combinations:\n",
    "        # Preprocess data\n",
    "\n",
    "        for model, hyperparameters in models_hyperparameters:\n",
    "\n",
    "            # Use ProcessPoolExecutor to parallelize the loop\n",
    "            with ThreadPoolExecutor(max_workers=num_cpu_cores-1) as executor:\n",
    "                # Prepare the list of arguments for each task\n",
    "                tasks = [\n",
    "                    (hp_set, model, hyperparameters, iter_aggregate, splits, df_physiology_video, df_annotations_video)\n",
    "                    for hp_set in itertools.product(*hyperparameters.values())\n",
    "                ]\n",
    "                \n",
    "                # Create a progress bar for ThreadPoolExecutor\n",
    "                progress = tqdm(total=len(tasks), desc=f\"Processing hyperparameters (threads: {threading.active_count()})\", unit=\"hp\", leave=False)\n",
    "\n",
    "                def callback(future):\n",
    "                    progress.update(1)\n",
    "                    result = future.result()\n",
    "                    results.append(result)\n",
    "\n",
    "                    # Update the all_results dictionary\n",
    "                    all_results[f\"{video}\"] = results\n",
    "\n",
    "                    # Save all_results as JSON\n",
    "                    with open('../results/scenario_2/clean_all_results_shallow_models.json', 'w') as f:\n",
    "                        json.dump(all_results, f, default=str, indent=4)\n",
    "\n",
    "\n",
    "                # Submit the tasks to the executor and add the callback\n",
    "                futures = [executor.submit(process_hp_set, *task_args) for task_args in tasks]\n",
    "                for future in futures:\n",
    "                    future.add_done_callback(callback)\n",
    "                # Close the progress bar\n",
    "                progress.close()\n",
    "                    \n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # if y_train.ndim > 1 and y_train.shape[1] > 1:\n",
    "    # Find the best result for each output variable\n",
    "    best_result_output_1 = results_df.loc[results_df['average_rmse_arousal'].idxmin()]\n",
    "    best_result_output_2 = results_df.loc[results_df['average_rmse_valence'].idxmin()]\n",
    "\n",
    "    # Concatenate the best results for each output variable to the best_results_df\n",
    "    best_results_df =pd.concat([best_results_df, best_result_output_1.to_frame().T, best_result_output_2.to_frame().T], ignore_index=True)\n",
    "    # else:\n",
    "    #     best_result = results_df.loc[results_df['average_rmse'].idxmin()]\n",
    "\n",
    "    #     best_results_df = best_results_df.append(best_result, ignore_index=True)\n",
    "\n",
    "    all_results[f\"{annotation_file}_{physiology_file}\"] = results_df.to_dict(orient='records')\n",
    "\n",
    "    # Save all_results as JSON\n",
    "    with open('../results/scenario_2/clean_all_results_shallow_models.json', 'w') as f:\n",
    "        json.dump(all_results, f, default=str, indent=4)\n",
    "\n",
    "    # Save best_results_df as CSV\n",
    "    best_results_df.to_csv('../results/scenario_2/clean_shallow_models_best_result.csv', index=False)\n",
    "\n",
    "print(\"\\nThe best combination of features and hyperparameters for each file pair is:\")\n",
    "print(best_results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
